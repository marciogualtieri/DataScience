---
title: 'Fake News Proliferation: An Interactive Graphical Exploration'
author: "Marcio Gualtieri"
date: "13 February 2017"
output:
  html_notebook:
    css: ../styles/style.css
    toc: yes
    toc_depth: 4
  html_document:
    css: ../styles/style.css
    toc: yes
    toc_depth: 4
---

# Overview

The data-set made available by [BuzzFeed](https://www.buzzfeed.com/) needed a somewhat extensive cleanup and for this reason I have created this notebook.

If you are only interested in the interactive graphs, you may go directly to the [presentation](../presentation/index.html).

BuzzFeed provided a simplified data-set as well, but they removed a lot of information, including much of the demographic, so I had to use the raw data, which can be found [here](https://github.com/BuzzFeedNews/2016-12-fake-news-survey), in my analysis.

# Installing the Required Packages

You might need to install the following packages if you don't already have them:

```{r, eval = FALSE}
install.packages("xtable")
install.packages("dplyr")
install.packages("plyr")
install.packages("stringr")
install.packages("reshape2")
```

# Importing the Required Packages

Once the libraries are installed, they need to be loaded as follows:

```{r}
suppressMessages(library(sp, quietly = TRUE))
suppressMessages(library(xtable))                        # Pretty printing dataframes
suppressMessages(library(plyr, warn.conflicts = FALSE))  # Manipulating dataframes
suppressMessages(library(dplyr, warn.conflicts = FALSE))
suppressMessages(library(stringr))                       # Manipulating strings
suppressMessages(library(reshape2))                      # Reshape columns into rows
```

# Loading Data

## Reading CSV Files

Let's first load the data-sets:

```{r}
data <- read.csv("../input/raw-data.csv", na.strings=c("NA", "NULL", ""), stringsAsFactors = FALSE)
headlines <- read.csv("../input/headlines.csv", na.strings=c("NA", "NULL", ""), stringsAsFactors = FALSE)
```

## Taking a Sample

```{r, results="asis"}
render_table_in_viewer_pane <- function(data, digits) {
  html <- print(xtable(data, digits = digits), type = "html", print.results=FALSE,
                sanitize.text.function = function(x) x)
  temp <- tempfile(fileext = ".html")
  cat(html, file = temp)
  rstudioapi::viewer(temp)
}

render_table <- function(data, digits = 2) {
  render_table_in_viewer_pane(data, digits)
  print(xtable(data, digits = digits), type = "html",
        sanitize.text.function = function(x) x)
}

sample_data_frame <- function(data, size) {
  sample_index <- sample(1:nrow(data), size)
  return(data[sample_index, ])
}

render_table(sample_data_frame(data, 6))
```

## Record Counting

```{r, results="asis"}
data_count <- function(data) {
  output <-               data.frame(measurement = "records", count = nrow(data))
  output <- rbind(output, data.frame(measurement = "variables", count = length(names(data))))
  return(output)
}

render_table(data_count(data))
```

# Missing Data

```{r, results="asis"}
missing_summary <- function(data) {
  count <- data %>% summarise_each(funs(sum(is.na(.))))
  output <- data.frame(variable = names(count), missing_count = t(count))
  rownames(output) <- 1:nrow(output)
  output <- output[output$missing_count > 0, ]
  return(output)
}

missing <- missing_summary(data[, !names(data) %in% c("classe") ])
render_table(missing)
```

<br/>
Quite a bit of missing data here. We will remove most of these columns in the next section.

# Data Cleanup

The headlines surveyed are the following:

```{r, results="asis"}
render_table(headlines)
```

<br/>
These are not available as a data-set, so I have built a file (`headlines.csv`) with this data. Given that is a reasonable amount of data, I believe that creating a `*.csv` file is cleaner than using code to create a data frame.

There are correspondent columns in the data-set for each of the headlines, that is, one for each "A", "B", "C", etc.

|Pattern                                            |Measurement|Values                                                                                            |
|---------------------------------------------------|-----------|--------------------------------------------------------------------------------------------------|
|`(LOOPDWD7_DWD8_)[A-K](_DWD7)`                     |Recall     |"yes" [I remember the headline], "no" and "unsure".                                               |
|`(LOOPDWD7_DWD8_)[A-K](_DWD8)`                     |Accuracy   |[the claim in the headline is] "somewhat accurate", "not very accurate" and "not at all accurate".|

The actual recall and accuracy values are encoded as numbers though, so follows data frames mapping each value to its correspondent code.

Recall codes:

```{r, results="asis"}
options <- c("yes", "no", "unsure")
recalls <- data.frame(id = 1:length(options), recall = options)
render_table(recalls)
```

<br/>
Accuracy codes:

```{r, results="asis"}
options <- c("very accurate", "somewhat accurate", "not very accurate", "not at all accurate")
accuracies <- data.frame(id = 1:length(options), accuracy = options)
render_table(accuracies)
```

<br/>
Let's try to analyze some columns which migh be interesting. First of all, recall, accuracy and order:

```{r}
variable_names <- function(data, pattern) names(data)[grep(pattern, names(data))]

recall_variables <- function(data) variable_names(data, "(LOOPDWD7_DWD8_)[A-K](_DWD7)")
accuracy_variables <- function(data) variable_names(data, "(LOOPDWD7_DWD8_)[A-K](_DWD8)")
```

|Variable                            |Value                                                                                                                  |
|------------------------------------|-----------------------------------------------------------------------------------------------------------------------|
|ID                                  |User ID.                                                                                                               |
|resp_age                            |Responder's age.                                                                                                       |
|resp_gender                         |Responder's gender, male: 1 or female: 2.                                                                              |
|HCAL_REGION1_Label_US               |U.S. states, string.                                                                                                   |
|HCAL_STDREGION_4CODES_Label_US      |U.S. regions, string.                                                                                                  |
|Weightvar                           |That's the weighting adjustment, to compensate for oversampling of any group.                                          |
|DP_INCOME                           |Income bands, as per data frame defined below.                                                                         |
|DP_EDUCATION_BAN                    |Education bands, as per data frame defined below.                                                                      |
|DP_ETHNICITY_BAN                    |Ethnicity, as per data frame defined below.                                                                            |
|DWD1                                |Political Afiliation, as per data frame defined below.                                                                 |
|DWD6                                |Presidential candidate, as per data frame defined below.                                                               |
|`(GRID_DWD11_)([1-9][0-9]*)(_DWD11)`|Scores for news sources, 1-15 representing sources as per data frame defined below. 1-4 scores as per data frame below.|


```{r}
news_source_score_variables <- function(data) variable_names(data, "(GRID_DWD11_)([1-9][0-9]*)(_DWD11)")
```

Many of the variable values are encoded as numbers though, so follows data frames mapping each value to its correspondent code.

```{r, results="asis"}
options <- c("Less than $25,000", "$25,000 to $34,999", "$35,000 to $49,999", "$50,000 to $74,999", "$75,000 to $99,999", "$100,000 to $149,999", "$150,000 or more")
income_bands <- data.frame(id = 1:length(options), income = options)
render_table(income_bands)
```

```{r, results="asis"}
options <- c("Less than high school", "High school graduate (includes equivalency)", "Some college, no degree", "Associate's degree", "Bachelor's degree", "Ph.D.", "Graduate or professional degree")
education_bands <- data.frame(id = 1:length(options), education = options)
render_table(education_bands)
```

```{r, results="asis"}
options <- c("White", "Black or African American", "Other race")
ethnicities <- data.frame(id = 1:length(options), ethnicity = options)
render_table(ethnicities)
```

```{r, results="asis"}
options <- c("Democrat", "Republican", "Independent", "Other")
parties <- data.frame(id = 1:length(options), party = options)
render_table(parties)
```

```{r, results="asis"}
options <- c("Hillary Clinton", "Donald Trump", "Gary Johnson", "Jill Stein", "Other")
candidates <- data.frame(id = 1:length(options), candidate = options)
render_table(candidates)
```

```{r, results="asis"}
options <- c("Is a major source of news for me", "Is a minor source of news for me", "Is rarely a source of news for me", "Is never a source of news for me", "I am not familiar with this news source")
news_sources_scores <- data.frame(id = 1:length(options), news_source_score = options)
render_table(news_sources_scores)
```

```{r, results="asis"}
options <- c("BuzzFeed", "Huffington Post", "New York Times", "Facebook", "Twitter", "Snapchat", "VICE", "CNN", "Vox", "Business Insider", "Washington Post", "Google News", "Yahoo News", "Drudge Report", "Fox News")
news_sources <- data.frame(id = 1:length(options), news_source = options)
render_table(news_sources)
```

<br/>
I'm going to start by removing columns that are not required at the moment:

```{r}
column_index <- function(name, data) {
  grep(paste0("^", name, "$"), colnames(data))
}

demographic_variables <- c("resp_age", "HCAL_REGION1_Label_US", "HCAL_STDREGION_4CODES_Label_US", "DP_INCOME", "DP_EDUCATION_BAN", "DP_ETHNICITY_BAN", "DWD1", "DWD6")

useful_columns <- c("ID",
                     "Weightvar",
                     demographic_variables,
                     recall_variables(data),
                     accuracy_variables(data),
                     news_source_score_variables(data))


data <- data[, useful_columns]
```

I'm going to decode these variable names and values (from the numeric code to description string) so they are easier to read:

```{r}
create_key_value_pairs <- function(keys, values) {
  pairs <- values
  names(pairs) <- keys
  return(pairs)
}

decode_column <- function(data, codes, column) {
  joint <- create_key_value_pairs(c(column), c("id"))
  data <- left_join(data, codes, by = joint)
  data <- data[, ! names(data) %in% c(column)]
  return(data)
}

data <- decode_column(data, income_bands, "DP_INCOME")
data <- decode_column(data, education_bands, "DP_EDUCATION_BAN")
data <- decode_column(data, ethnicities, "DP_ETHNICITY_BAN")
data <- decode_column(data, parties, "DWD1")
data <- decode_column(data, candidates, "DWD6")
```

Some of the variables only require a change of name, decoding not necessary:

```{r}
data <- plyr::rename(data, c("resp_age"="age", "HCAL_REGION1_Label_US"="state", "HCAL_STDREGION_4CODES_Label_US"="region"))
demographic_variables <- c("age", "state", "region", "income", "ethnicity", "education", "party", "candidate")

recall_variables <- function(data) variable_names(data, "recall_[A-K]")
accuracy_variables <- function(data) variable_names(data, "accuracy_[A-K]")
```

Recalls, accuracies and news sources are a bit more complicated case, so I have created functions with the purpose of decoding their values and renaming them.

First recall:

```{r}
rename_columns <- function(data, from_names, to_names) {
  renaming <- create_key_value_pairs(from_names, to_names)
  data <- plyr::rename(data, renaming)
  return(data)
}

rename_headline_column <- function(data, from_name, to_prefix, headline_code) {
  to_column <- paste0(to_prefix, "_", headline_code)
  data <- rename_columns(data, c(to_prefix), c(to_column))
  data <- data[, ! names(data) %in% c(from_name)]
  return(data)
}

rebuild_column <- function(data, codes, headline_code, prefix, suffix, to_prefix) {
  column <- paste0(prefix, headline_code, suffix)
  joint <- create_key_value_pairs(c(column), c("id"))
  full_join(data, recalls, by = joint)
  data <- full_join(data, codes, by = joint)
  data <- rename_headline_column(data, column, to_prefix, headline_code)
  return(data)
}

rebuild_recall_columns <- function(data) {
  for (headline_code in headlines$headline_id) {
    data <- rebuild_column(data = data, codes = recalls, headline_code, prefix = "LOOPDWD7_DWD8_", suffix = "_DWD7", to_prefix = "recall")
  }
  return(data)
}

data <- rebuild_recall_columns(data)
```

Then accuracy:

```{r}
rebuild_accuracy_columns <- function(data) {
  for (headline_code in headlines$headline_id) {
    data <- rebuild_column(data = data, codes = accuracies, headline_code, prefix = "LOOPDWD7_DWD8_", suffix = "_DWD8", to_prefix = "accuracy")
  }
  return(data)
}

data <- rebuild_accuracy_columns(data)
```

Then news sources:

```{r}
compute_news_source_variable_name <- function(string) paste0("score_", str_replace_all(string, "[^A-Za-z]", "_"))

rename_news_source_column <- function(data, news_sources, column, news_source_variable_index) {
  news_source_variable_name <- compute_news_source_variable_name(news_sources$news_source[news_source_variable_index])
  data <- rename_columns(data, c("news_source_score"), c(news_source_variable_name))
  data <- data[, ! names(data) %in% c(column)]
  return(data)
}

rebuild_news_source_column <- function(data, news_source_variable_index) {
  column <- paste0("GRID_DWD11_", news_source_variable_index, "_DWD11")
  joint <- create_key_value_pairs(c(column), c("id"))
  data <- full_join(data, news_sources_scores, by = joint)
  data <- rename_news_source_column(data, news_sources, column, news_source_variable_index)
  return(data)
}

rebuild_news_source_columns <- function(data) {
  for(index in news_sources$id) {
    data <- rebuild_news_source_column(data, index)
  }
  return(data)
}

data <- rebuild_news_source_columns(data)
```

# All Cleaned-up Data-set

Should be much more readable now. In the next sections we will compute the statistics and build our leaflet map.

## Taking a Sample

Let's now take a sample from the data-set and see what it looks like:

```{r, results = "asis"}
render_table(sample_data_frame(data, 6))
```

<br/>
Here a look at the variables in the data-set if you didn't bother to go through the data cleanup section:

```{r}
str(data)
```

# Breaking Recall, Accuracy & News Sources Scores

For convinience, I'm going to break the original data into three, for recall, accuracy, and news souce score.

## Recall & Accuracy

```{r}
extract_headline <- function(name, headlines) return(str_match_all(name, "(accuracy|recall)_([A-K])")[[1]][3])

recall_data <- data[, c("ID", "Weightvar", demographic_variables, recall_variables(data))]
accuracy_data <- data[, c("ID", "Weightvar", demographic_variables, accuracy_variables(data))]

rebuild_column <- function(data, column) {
  data <- melt(data, id.vars=c("ID", "Weightvar", demographic_variables))
  data$variable <- sapply(data$variable, extract_headline)
  data <- rename_columns(data, c("variable", "value"), c("headline_id", column))
  return(data)
}

accuracy_data <- rebuild_column(accuracy_data, "accuracy")
recall_data <- rebuild_column(recall_data, "recall")
```

For simplicity, I'm going to generate a binary variable for the responder guessing the headline veracity correctly or incorrectly:

```{r, results="asis"}
guessed_correctly <- function(headline_status, accuracy) {
  if(is.na(headline_status) | is.na(accuracy)) return(NA)
  else if(headline_status == "Fake" & grepl("not", accuracy) | 
          headline_status == "Real" & ! grepl("not", accuracy)) return("yes")
  else return("no")
}

add_guessed_correctly <- function(data) {
  data$guessed_correctly <- mapply(guessed_correctly, data$headline_status, data$accuracy)
  data <- data[!is.na(data$guessed_correctly), ]
  return(data)
}

accuracy_data <- left_join(accuracy_data, headlines, by = "headline_id")
accuracy_data <- add_guessed_correctly(accuracy_data)

render_table(sample_data_frame(accuracy_data, 6))
```

<br/>
The same for the responder having heard the headline:

```{r, results="asis"}
recall_fake_headline <- function(headline_status, recall) {
  if(is.na(headline_status) | headline_status == "Real" | is.na(recall)) return(NA)
  else if(headline_status == "Fake" & grepl("yes", recall)) return("yes")
  else return("no")  
}

add_recall_fake_headline <- function(data) {
  data$recall_fake_headline <- mapply(recall_fake_headline, data$headline_status, data$recall)
  data <- data[!is.na(data$recall_fake_headline), ]
  return(data)
}

recall_data <- left_join(recall_data, headlines, by = "headline_id")
recall_data <- add_recall_fake_headline(recall_data)

recall_data
render_table(sample_data_frame(recall_data, 6))
```

<br/>

## News source

```{r, results="asis"}
news_source_score_variables <- function(data) variable_names(data, "score_.+")

extract_news_source <- function(name) {
  name <- str_match_all(name, "score_(.+)")[[1]][2]
  name <- str_replace_all(name, "_", " ")
  return(name)
}

rebuild_column <- function(data) {
  data <- data[, c("ID", "Weightvar", demographic_variables, news_source_score_variables(data))]
  data <- melt(data, id.vars=c("ID", "Weightvar", demographic_variables))
  data$variable <- sapply(data$variable, extract_news_source)
  data <- rename_columns(data, c("variable", "value"), c("news_source", "news_source_score"))
  return(data)
}

news_source_score_data <- rebuild_column(data)
render_table(sample_data_frame(news_source_score_data, 6))
```

<br/>

# Save Data to CSV

```{r}
write.csv(recall_data, file = "../output/recall_data.csv", row.names = FALSE)
write.csv(accuracy_data, file = "../output/accuracy_data.csv", row.names = FALSE)
write.csv(news_source_score_data, file = "../output/news_source_score_data.csv", row.names = FALSE)
```

