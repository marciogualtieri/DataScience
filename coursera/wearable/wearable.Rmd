---
output:
  md_document:
    toc: yes
    toc_depth: 4
    variant: markdown_github
    df_print: "kable"
---

<h1>Wearable Computing: Human Activity Recognition Using Smartphones</h1>

# Installing the Required Packages

You might need to install the following packages if you don't already have them:

```{r, eval = FALSE}
install.packages("xtable")
install.packages("dplyr")
```

Just uncomment the packages you need and run this chunk before you run the remaining ones in this notebook.

# Importing the Required Packages

Once the libraries are installed, they need to be loaded as follows:

```{r}
suppressMessages(library(xtable))  # Pretty printing dataframes
suppressMessages(library(dplyr))
```

# Loading Data

The data is packaged in a zip file and can be downloaded from the given remove URL:

```{r}
download_zipped_data <- function(url, destination) {
  temp_file <- tempfile()
  download.file(url, temp_file)
  unzip(zipfile = temp_file, exdir = destination)
  unlink(temp_file)
}

download_zipped_data("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",
                     "./data")
```

# Description of Raw Data

Here are the the unzipped files contained in the data-set package:

```{r}
list.files(path = "./data", recursive = TRUE)
```

Follows a short description for each one of the available files:

|File                        |Commentary                                                                                     |
|----------------------------|-----------------------------------------------------------------------------------------------|
|README.txt                  |An overview of the experiment.                                                                 |
|features_info.txt           |A brief description of the measurements contained in the data-set.                             |    
|features.txt                |A list of the available variables (measurements) with their respective index numbers.          |
|activity_labels.txt         |A list of activities, i.e., walking, sitting, stading, etc with their respective index numbers.|
|train/X_train.txt           |"X" is a matrix with features for training data.                                               |
|train/y_train.txt           |"Y" is a vector with the label/response for the training data.                                 |
|train/subject_train.txt     |"subject" is a vector with the subject ID's for the training data.                             |
|train/Inertial Signals/*.txt|The original pre-processed training data.                                                      |
|test/X_test.txt             |"X" is a matrix with features for test data.                                                   |
|test/y_test.txt             |"Y" is a vector with the label/response for the test data.                                     |
|test/subject_test.txt       |"subject" is a vector with the subject ID's for the test data.                                 |
|test/Inertial Signals/*.txt |The original pre-processed test data.                                                          |

For the purpose of data exploration, we are not interested in the pre-processed data, thus, we're going to work with the following files:

* train/X_train.txt (training feature data)
* train/y_train.txt (training label data)
* test/X_test.txt (test feature data)
* test/y_test.tx (test label data)
* features.txt (feature names which map to feature index numbers)
* activity_labels.txt (human-readable labels which map to activity index numbers)

# Loading Data

```{r}
test_data <- read.table("./data/UCI HAR Dataset/test/X_test.txt", stringsAsFactors = FALSE)
dim(test_data)
```

```{r}
train_data <- read.table("./data/UCI HAR Dataset/train/X_train.txt", stringsAsFactors = FALSE)
dim(train_data)
```

The feature data contains `r dim(test_data)[2]` feature variables and `r ncol(test_data) + ncol(train_data)` observations (adding up testing and training data-sets).

```{r}
features <- read.table("./data/UCI HAR Dataset/features.txt", stringsAsFactors = FALSE)
str(features)
```

As expected, the feature names data contains `r ncol(features)`, which matches with the number of columns in the feature data.

Note that 

```{r}
feature_names <- features[, 2]
sample(feature_names, 6)
```


```{r}
test_labels <- read.table("./data/UCI HAR Dataset/test/y_test.txt", stringsAsFactors = FALSE)
dim(test_labels)
```

```{r}
train_labels <- read.table("./data/UCI HAR Dataset/train/y_train.txt", stringsAsFactors = FALSE)
dim(train_labels)
```

```{r}
variables <- c(feature_names, "ActivityID")
mean_variables <- grep("mean\\(\\)", variables, value = TRUE)
std_variables <- grep("std\\(\\)", variables, value = TRUE)
sample(variables, 6)
sample(mean_variables, 6)
sample(std_variables, 6)
```

```{r}
add_labels <- function(data, labels) {
  data <- cbind(data, labels)
  data
}

test_data <- add_labels(test_data, test_labels)
dim(test_data)
```


```{r}
add_variable_names <- function(data) {
  names(data) <- variables
  data
}

test_data <- add_variable_names(test_data)
sample(names(test_data), 6)
```

```{r}
select_mean_and_std_variables <- function(data)
  data[, c(mean_variables, std_variables, "ActivityID")]


test_data <- select_mean_and_std_variables(test_data)
names(test_data)
```

```{r}
normalize_variable_names <- function(data) {
  names(data) <- make.names(names(data))
  names(data) <- gsub("\\.", "", names(data))
  names(data) <- gsub("mean", "Mean", names(data))
  names(data) <- gsub("std", "Sigma", names(data))
  names(data) <- gsub("Acc", "Acceleration", names(data))
  names(data) <- gsub("Mag", "Magnitude", names(data))
  data
}

sample_data_frame <- function(data, size) {
  sample_index <- sample(1:nrow(data), size)
  return(data[sample_index, ])
}

test_data <- normalize_variable_names(test_data)
sample_data_frame(test_data, 6)
```

```{r}
activities <- read.table("./data/UCI HAR Dataset/activity_labels.txt")
dim(activities)
```

```{r}
names(activities) <- c("ActivityID", "ActivityLabel")
str(activities)
```
```{r}
add_activity_label_variable <- function(data, activities) {
  data <- merge(data, activities)
  data <- data[, !names(data) %in% c("ActivityID")]
  data
}

test_data <- add_activity_label_variable(test_data, activities)
sample_data_frame(test_data, 6)
```

```{r}
cleanup_data <- function(data, labels) {
  data <- add_labels(data, labels)
  data <- add_variable_names(data)
  data <- select_mean_and_std_variables(data)
  data <- normalize_variable_names(data)
  add_activity_label_variable(data, activities)
}

train_data <- cleanup_data(train_data, train_labels)
sample_data_frame(train_data, 6)
```

```{r}
all_data <- rbind(test_data, train_data)
dim(all_data)
```


```{r}
activity_averages_data <- all_data %>% group_by(ActivityLabel) %>% summarise_each(funs(mean))
activity_averages_data
```

```{r}
sample_data_frame(all_data, 6)
```

